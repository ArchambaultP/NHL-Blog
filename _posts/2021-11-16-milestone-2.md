---
layout: post
title: Milestone 2
---

# Question 2: Feature Engineering 1

## 1

The first feature to be plotted is distance:
![](../images/Shot%20Count%20per%20Distance.png)
As we can see, the amount of shots taken further than about 60 meters drops drastically.
This is probably the distance at which most player become comfortable making shots.
The number of no-goal shots seem to fluctuate with a minimum around 600 before this 60 meters mark.
However, the number of goals decreases in a non-linear way until almost 0 at this 60 meters mark.
This decrease almost looks like an exponential one.
From this drop alone, we can clearly identify distance as a good prediction feature.

The next feature to be plotted is angle:
![](../images/Shot%20Count%20per%20Angle.png)
We can see that the more the absolute value of the angle increases, the less goals there are.
However, for the number of non-goal shots, it isn't as straightforward.
It seems as though there are a lot of shots at zero angle.
But then, there is a sudden drop from about 4 degrees to 18 degrees followed by an increase from about 22 degrees to about 30 degrees.
This second local maxima seems odd. It would suggest that this angle is an angle that most players feel comfortable to shoot from.
In any case, this increase in shots doesn't come with a visible increase in goals.

Next, we can plot the shots as a function of both distance and angle.
![](../images/Shots%20in%20Distance-Angle%20Feature%20Space.png)
This particular shape illustrates the physical limitations of the game.
As you go further from the net, there is less possible angles to choose from to shoot at the net.
Furthermore, it is possible that these angles don't extend to both sides of the rink as the further you are, the harder it is to aim correctly at the net from an angle.
This explains the reason why there is a higher shot rate at 0 degrees, it accounts for both close and far away shots.
From this cloud of points, we can also deduce that it will be hard for a simple logistic regression to clearly separate goals from no-goals.

## 2

The fist goal rates chart is plotted against distance:
![](../images/Goal%20Rates%20per%20Shot%20Distance.png)
As we can see, initially, the rate seems to decrease as distance increases.
But after the 60-75 meters mark, the rates become a bit less stable and increases.
By referring to the plot of shot count per distance, we conclude that the rates before the 60 meters have a higher confidence interval than those further back.
This is because there is a lot more data which means that these rates are a lot more representative.
Since after this mark there is little to no data, it explains why the rates suddenly aren't stable.
It is also possible that there are other factors or features at play that should be included to understand this distribution.

The second goal rate chart is plotted against shot angle.
![](../images/Goal%20Rates%20per%20Shot%20Angle.png)
Similarly to the goal counts per angle, the trend in shot rates seems to peak at zero degrees and slowly decreases as the angle increases.
This makes sense with the intuition that shooting in the net is easier from the front than from the sides.

## 3
![](../images/Goal%20Count%20per%20Distance.png)
In this histogram, we see that the number of goals with empty nets varies from zero to around 10 across all distances.
On the other hand, the number goals without empty nets peaks close to the net and then decreases as the distance gets further away.
Further than the 60 meters mark, we start to see more goals with empty nets than goals with non-empty nets.
This makes sense with the intuition that the further the shot is from the net, the easier it is for the goalie to block it.
However, if there is no goalie, the shots become a lot more feasible.
Furthermore, it makes sense with the fluctuation of goal rates seen in the histogram of goal rates per distance.
This feature is probably a good indicator of if a shot will succeed or not.

On another note, it seems like there are a number of goals at around 165 meters that are with a non-empty net.
This doesn't follow the trend and seems like either outlier data or noisy data.
It is possible that these shots have bad x/y coordinates which would explain why it doesn't follow the trend.

# Baseline Models

## 1. Linear Regression Model Trained on Distance Feature

After training the base linear regression model on distance, the validation accuracy obtained is 91%.
At first, this value seems good and the model seems to perform splendidly!
However, if we remember how the data wasn't linearly separable in the shot counts per distance histogram.
We can already deduce that something is going wrong...
This model seems to perform too well for the data that was observed.
To look further into this, we have plotted the predictions vs the actual values depending on the distance:

![](../images/Goal%20Predictions%20Compared%20to%20Actual%20Goals%20Based%20on%20Distance%20Feature.png)

As we can see, the trained model only predicts non-goals.
This still gives a good accuracy because no-goals shots are the most common type of shots by far.
Effectively, this linear regression model hasn't learned anything and isn't of any value to predict scores.
This is probably due to the fact that the data isn't linearly separable and that for all distances, there are more no-goals than goals.
To learn a better decision boundary, more features wil be required.

## 3. Logistic Regression Classifiers Performance on Different Features

![](../images/Baseline%20Models%20ROC.png)

As expected, the random baseline generated a linear line from 0 to 1 on the ROC curve.
We can see that the model trained on angle only doesn't perform much better than the random baseline.
This is probably due to the fact that the data is reflected at zero and is therefore even less linearly separable than if we took the angle's absolute value.
The feature distance definitely shows an improvement and seems to be the best performing model.
What is surprising is that the model trained on both features performed worse than the one on distance alone.
This might indicate how the angle feature's distribution is harming the model's ability to predict.

![](../images/Baseline%20Models%20Goal%20Rates.png)

As seen through the random baseline, it seems like the total goal rate is around just under 10%.
The ideal line would be a straight line going from 100% to 0% as this would mean that the model predicts the actual true probability.
However, even the best model is far from this goal.
It seems like none of the most probable shots according to the models were actually goals.
The models including distance seem to be most precise when they predict in the 90% percentile and higher
The angle model seems to predict very poorly as the high percentiles have lower goal rates than the actual goal rate.
This means that when the model has higher confidence than all its other predictions, it is making a mistake.
On the other hand, the models including the distance feature seem to be more precise as they are more confident in their own predictions.

![](../images/Baseline%20Models%20Cumulative%20Percentage%20Of%20Goals.png)

Since all the random baseline's predictions are of 50%, all percentiles return a predicted probability of 50%.
Therefore, all the percentiles contain 100% of the goals because they are all equal.
When predictions are different, this looks a lot more like the ROC curve shown earlier.
All three models have similar curves as before.
Even if the distance model seemed to have a high goal rate for its high percentiles, these don't have a high cumulative number of goals.
This means that there are likely only a few goals that are predicted with high accuracy.
This model and the one trained on both features accumulate a lot of goals as their shot probabilities are higher than 50%.
This means that they at least are partly doing something right.
They can identify when goals are more probable.
However, with the goal rates graph, this also means that for most goals, the model still isn't very precise.

![](../images/Baseline%20Models%20Reliability.png)

As expected, the random baseline is very poorly calibrated because it always predicts a 50% change no matter what.
This means we cannot consider this probability as the true probability.
For the other models, we surprisingly don't have a wide range of mean predicted probabilities.
This indicates that all logistic regressions predict with very low probabilities.
This makes sense with the fact that the models predict no goals all the time because the data is not linearly separable and that is the most common label.
We can make out that the angle classifier mostly predicts the same probability and deviates a bit from the prefect calibration.
However, for the model including distance, we have a wider range of mean predicted probabilities.
This shows that the distance helps differentiate the true shot probabilities.
These models also seem to be well calibrated.
Further improvements for the logistic regression is probably only possible with better and more features.

## 4 Model Links:

* [Uniform Random Baseline](https://www.comet.ml/charlescol/milestone-2/58fc9012caa042e3bf41033a8077c09b)
* [Distance Logistic Regression](https://www.comet.ml/charlescol/milestone-2/5396ea6a16014660b306e9816cd8ecbf)
* [Angle Logistic Regression](https://www.comet.ml/charlescol/milestone-2/e1598af346ce4ed9bce68d7d07bb81d0)
* [Distance-Angle Logistic Regression](https://www.comet.ml/charlescol/milestone-2/d3fb90021c214530962e81987dba6723)

# Question 4: Feature Engineering 2

New features have been added to DataFrame. You can find the list of these new features and their explanation above:

| Feature | Explanation |
|------------|-------------|
| Game_seconds | Total number of seconds elapsed in the game.  |
| Last_event_type | Type of event that occurred immediately before the current event.  |
| Last_coordinates.x | Coordinates x of the last event (m). |
| Last_coordinates.y | Coordinates y of the last event (m). |
| Time_last_event | Total number of seconds elapsed since the last event. |
| Distance_last_event | Distance in meters from the last event. |
| Rebound | Indicates whether the last event was a shot by the same team (boolean). |
| Angle_change | In case of a rebound, it indicates the difference between the angles of the first and second shots. |
| Speed | In case of a rebound, it indicates the speed in m/s(distance from the last event / time elapsed since last event). |
| TimeSincePP | Time elasped since current team is in power-play (other team is penalized). If the opponent has another penalty, the timer continues to run until all penalties expire. |
| FriendPlayers | Number of skaters from the same team on the ice (consediring the penalties). |
| OpposingPlayers | Number of skaters from the opponent team on the ice (consediring the penalties). |

The complete dataset, including these new features, from the game "Winnipeg vs Washington", played on March 12, 2018, can be found in the experiment:
<a href="https://www.comet.ml/charlescol/milestone-2-feature-engineering-data/226077a645814e6986ad141c7f8579be?experiment-tab=assets">Comet Dataframe - Winnipeg vs Washington</a>
