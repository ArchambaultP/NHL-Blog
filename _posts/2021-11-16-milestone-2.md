---
layout: post
title: Milestone 2
---

# Question 2: Feature Engineering 1

## 1

The first feature to be plotted is distance:
![](../images/Shot%20Count%20per%20Distance.png)
As we can see, the amount of shots taken further than about 60 meters drops drastically.
This is probably the distance at which most player become comfortable making shots.
The number of no-goal shots seem to fluctuate with a minimum around 600 before this 60 meters mark.
However, the number of goals decreases in a non-linear way until almost 0 at this 60 meters mark.
This decrease almost looks like an exponential one.
From this drop alone, we can clearly identify distance as a good prediction feature.

The next feature to be plotted is angle:
![](../images/Shot%20Count%20per%20Angle.png)
We can see that the more the absolute value of the angle increases, the less goals there are.
However, for the number of non-goal shots, it isn't as straightforward.
It seems as though there are a lot of shots at zero angle.
But then, there is a sudden drop from about 4 degrees to 18 degrees followed by an increase from about 22 degrees to about 30 degrees.
This second local maxima seems odd. It would suggest that this angle is an angle that most players feel comfortable to shoot from.
In any case, this increase in shots doesn't come with a visible increase in goals.

Next, we can plot the shots as a function of both distance and angle.
![](../images/Shots%20in%20Distance-Angle%20Feature%20Space.png)
This particular shape illustrates the physical limitations of the game.
As you go further from the net, there is less possible angles to choose from to shoot at the net.
Furthermore, it is possible that these angles don't extend to both sides of the rink as the further you are, the harder it is to aim correctly at the net from an angle.
This explains the reason why there is a higher shot rate at 0 degrees, it accounts for both close and far away shots.
From this cloud of points, we can also deduce that it will be hard for a simple logistic regression to clearly separate goals from no-goals.

## 2

The fist goal rates chart is plotted against distance:
![](../images/Goal%20Rates%20per%20Shot%20Distance.png)
As we can see, initially, the rate seems to decrease as distance increases.
But after the 60-75 meters mark, the rates become a bit less stable and increases.
By referring to the plot of shot count per distance, we conclude that the rates before the 60 meters have a higher confidence interval than those further back.
This is because there is a lot more data which means that these rates are a lot more representative.
Since after this mark there is little to no data, it explains why the rates suddenly aren't stable.
It is also possible that there are other factors or features at play that should be included to understand this distribution.

The second goal rate chart is plotted against shot angle.
![](../images/Goal%20Rates%20per%20Shot%20Angle.png)
Similarly to the goal counts per angle, the trend in shot rates seems to peak at zero degrees and slowly decreases as the angle increases.
This makes sense with the intuition that shooting in the net is easier from the front than from the sides.

## 3
![](../images/Goal%20Count%20per%20Distance.png)
In this histogram, we see that the number of goals with empty nets varies from zero to around 10 across all distances.
On the other hand, the number goals without empty nets peaks close to the net and then decreases as the distance gets further away.
Further than the 60 meters mark, we start to see more goals with empty nets than goals with non-empty nets.
This makes sense with the intuition that the further the shot is from the net, the easier it is for the goalie to block it.
However, if there is no goalie, the shots become a lot more feasible.
Furthermore, it makes sense with the fluctuation of goal rates seen in the histogram of goal rates per distance.
This feature is probably a good indicator of if a shot will succeed or not.

On another note, it seems like there are a number of goals at around 165 meters that are with a non-empty net.
This doesn't follow the trend and seems like either outlier data or noisy data.
It is possible that these shots have bad x/y coordinates which would explain why it doesn't follow the trend.

# Baseline Models

## 1. Linear Regression Model Trained on Distance Feature

After training the base linear regression model on distance, the validation accuracy obtained is 91%.
At first, this value seems good and the model seems to perform splendidly!
However, if we remember how the data wasn't linearly separable in the shot counts per distance histogram.
We can already deduce that something is going wrong...
This model seems to perform too well for the data that was observed.
To look further into this, we have plotted the predictions vs the actual values depending on the distance:

![](../images/Goal%20Predictions%20Compared%20to%20Actual%20Goals%20Based%20on%20Distance%20Feature.png)

As we can see, the trained model only predicts non-goals.
This still gives a good accuracy because no-goals shots are the most common type of shots by far.
Effectively, this linear regression model hasn't learned anything and isn't of any value to predict scores.
This is probably due to the fact that the data isn't linearly separable and that for all distances, there are more no-goals than goals.
To learn a better decision boundary, more features wil be required.

## 3. Logistic Regression Classifiers Performance on Different Features

![](../images/Baseline%20Models%20ROC.png)

As expected, the random baseline generated a linear line from 0 to 1 on the ROC curve.
We can see that the model trained on angle only doesn't perform much better than the random baseline.
This is probably due to the fact that the data is reflected at zero and is therefore even less linearly separable than if we took the angle's absolute value.
The feature distance definitely shows an improvement and seems to be the best performing model.
What is surprising is that the model trained on both features performed worse than the one on distance alone.
This might indicate how the angle feature's distribution is harming the model's ability to predict.

![](../images/Baseline%20Models%20Goal%20Rates.png)

As seen through the random baseline, it seems like the total goal rate is around just under 10%.
The ideal line would be a straight line going from 100% to 0% as this would mean that the model predicts the actual true probability.
However, even the best model is far from this goal.
It seems like none of the most probable shots according to the models were actually goals.
The models including distance seem to be most precise when they predict in the 90% percentile and higher
The angle model seems to predict very poorly as the high percentiles have lower goal rates than the actual goal rate.
This means that when the model has higher confidence than all its other predictions, it is making a mistake.
On the other hand, the models including the distance feature seem to be more precise as they are more confident in their own predictions.

![](../images/Baseline%20Models%20Cumulative%20Percentage%20Of%20Goals.png)

Since all the random baseline's predictions are of 50%, all percentiles return a predicted probability of 50%.
Therefore, all the percentiles contain 100% of the goals because they are all equal.
When predictions are different, this looks a lot more like the ROC curve shown earlier.
All three models have similar curves as before.
Even if the distance model seemed to have a high goal rate for its high percentiles, these don't have a high cumulative number of goals.
This means that there are likely only a few goals that are predicted with high accuracy.
This model and the one trained on both features accumulate a lot of goals as their shot probabilities are higher than 50%.
This means that they at least are partly doing something right.
They can identify when goals are more probable.
However, with the goal rates graph, this also means that for most goals, the model still isn't very precise.

![](../images/Baseline%20Models%20Reliability.png)

As expected, the random baseline is very poorly calibrated because it always predicts a 50% change no matter what.
This means we cannot consider this probability as the true probability.
For the other models, we surprisingly don't have a wide range of mean predicted probabilities.
This indicates that all logistic regressions predict with very low probabilities.
This makes sense with the fact that the models predict no goals all the time because the data is not linearly separable and that is the most common label.
We can make out that the angle classifier mostly predicts the same probability and deviates a bit from the prefect calibration.
However, for the model including distance, we have a wider range of mean predicted probabilities.
This shows that the distance helps differentiate the true shot probabilities.
These models also seem to be well calibrated.
Further improvements for the logistic regression is probably only possible with better and more features.

## 4 Model Links:

* [Uniform Random Baseline](https://www.comet.ml/charlescol/milestone-2/58fc9012caa042e3bf41033a8077c09b)
* [Distance Logistic Regression](https://www.comet.ml/charlescol/milestone-2/5396ea6a16014660b306e9816cd8ecbf)
* [Angle Logistic Regression](https://www.comet.ml/charlescol/milestone-2/e1598af346ce4ed9bce68d7d07bb81d0)
* [Distance-Angle Logistic Regression](https://www.comet.ml/charlescol/milestone-2/d3fb90021c214530962e81987dba6723)

# Question 4: Feature Engineering 2


New features have been added to DataFrame. You can find the list of these new features and their explanation above:
{: style="text-align: justify"}

| Feature | Explanation |
|------------|-------------|
| Game_seconds | Total number of seconds elapsed in the game.  |
| Last_event_type | Type of event that occurred immediately before the current event.  |
| Last_coordinates.x | Coordinates x of the last event (m). |
| Last_coordinates.y | Coordinates y of the last event (m). |
| Time_last_event | Total number of seconds elapsed since the last event. |
| Distance_last_event | Distance in meters from the last event. |
| Rebound | Indicates whether the last event was a shot by the same team (boolean). |
| Angle_change | In case of a rebound, it indicates the difference between the angles of the first and second shots. |
| Speed | In case of a rebound, it indicates the speed in m/s(distance from the last event / time elapsed since last event). |
| TimeSincePP | Time elasped since current team is in power-play (other team is penalized). If the opponent has another penalty, the timer continues to run until all penalties expire. |
| FriendPlayers | Number of skaters from the same team on the ice (consediring the penalties). |
| OpposingPlayers | Number of skaters from the opponent team on the ice (consediring the penalties). |

The complete dataset, including these new features, from the game "Winnipeg vs Washington", played on March 12, 2018, can be found in the experiment:
<a href="https://www.comet.ml/charlescol/milestone-2-feature-engineering-data/226077a645814e6986ad141c7f8579be?experiment-tab=assets">Comet Dataframe - Winnipeg vs Washington</a>


# Question 5: Advanced Models (XGBoost)



## 5.1 

First, we trained a XGBoost classifier using only the distance and angle features (similar to part 3). The corresponding curves can be visualized below:
{: style="text-align: justify"}

<table style="width:100%">
    <tr>
        <td><img src="/images/xgb_base_AUC.png"></td>
        <td><img src="/images/xgb_base_goal_rate.png"></td>
    </tr>
        <tr>
        <td><img src="/images/xgb_base_cumulative_goals.png"></td>
        <td><img src="/images/xgb_base_calibration.png"></td>
    </tr>
    <tr>
        <td colspan="2"><center>XGBoost Base Model</center></td>
    </tr>
</table>


Using XGBoost only with the distance and angle features, the curves found were very close to those generated by models with linear rules. The AUC was a little better and the calibration curve was a little more uniform.
{: style="text-align: justify"}

The corresponding experiment can be found in:
<a href="https://www.comet.ml/charlescol/milestone-2/0dc3f880a8cc4a16801dc18c73039768?experiment-tab=chart&showOutliers=true&smoothing=0&transformY=smoothing&xAxis=wall">XGBoost - Base</a>



## 5.2 

The next step was to train an XGBoost classifier using all the features created in Part 4. In this model, we did cross-validated grid searching to optimize the error objective in relation to the  'max_depth' and 'min_child_weight' hyperparameters. According to the xgboost library (https://xgboost.readthedocs.io/en/stable/parameter.html) documentation, these hyperparameters) can be defined as:
{: style="text-align: justify"}

* max_depth [default=6]: *Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit. 0 is only accepted in lossguide growing policy when tree_method is set as hist or gpu_hist and it indicates no limit on depth. Beware that XGBoost aggressively consumes memory when training a deep tree.*
{: style="text-align: justify"}

* min_child_weight [default=1]: *Minimum sum of instance weight (hessian) needed in a child. If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight, then the building process will give up further partitioning. In linear regression task, this simply corresponds to minimum number of instances needed to be in each node. The larger min_child_weight is, the more conservative the algorithm will be.* 
{: style="text-align: justify"}

<table style="width:100%">
    <tr>
        <td><img src="/images/xgb_grid_AUC.png"></td>
        <td><img src="/images/xgb_grid_goal_rate.png"></td>
    </tr>
        <tr>
        <td><img src="/images/xgb_grid_cumulative_goals.png"></td>
        <td><img src="/images/xgb_grid_calibration.png"></td>
    </tr>
    <tr>
        <td colspan="2"><center>XGBoost with complete dataset and grid search</center></td>
    </tr>
</table>

In this case, we can observe an important increase in all parameters evaluated in the generated graphs. The AUC reaches 0.78. The cumulative % of goals curve gets an expected shape (a straight line running from 100% to 0%). The calibration curve shows a linear result, with a range of predictions stretched to zero% compared to the previous model (it can better predict shots that have a very low probability).
{: style="text-align: justify"}


The corresponding experiment can be found in:
<a href="https://www.comet.ml/charlescol/milestone-2/3d6769edb6c74582aff80c8dcbc8b7a4?experiment-tab=chart&showOutliers=true&smoothing=0&transformY=smoothing&xAxis=wall">XGBoost - Grid Search</a>


## 5.3 

The last XGBoost model in this section was obtained by applying the feature selection in the previous one. To do this, we use a simple strategy: we rank resources by highest  importance calculated using two different approaches, the get_score function and the SHAP library, both supported by an XGBoost classifier. After that, we arbitrarily choose the first 10 features in each case and test the accuracy in the validation set to get the best one. In this case, the "best" features were selected by get_score. The feature set was (important to mention that the Shot_type and Last_event_type categorical features were converted to a hot feature and some of them appear in the selected feature set):
{: style="text-align: justify"}

* ['EmptyNet', 'Period', 'goalDist', 'HIT', 'Coordinates.y', 'GIVEAWAY', 'Change_angle', 'STOP', 'OpposingPlayers', 'Time_last_event'] 

<table style="width:100%">
    <tr>
        <td><img src="/images/xgb_feat_AUC.png"></td>
        <td><img src="/images/xgb_feat_goal_rate.png"></td>
    </tr>
        <tr>
        <td><img src="/images/xgb_feat_cumulative_goals.png"></td>
        <td><img src="/images/xgb_feat_calibration.png"></td>
    </tr>
    <tr>
        <td colspan="2"><center>XGBoost with feature selection (10 features)</center></td>
    </tr>
</table>

The curves found were very similar to those found in that model trained with the complete dataset. Although the results were not superior, the fact that they present similar numbers shows that we have little additional information contained in the other features of the dataset.

The corresponding experiment can be found in:
<a href="https://www.comet.ml/charlescol/milestone-2/37f08690641e4c7296138473387b4eeb?experiment-tab=chart&showOutliers=true&smoothing=0&transformY=smoothing&xAxis=wall">XGBoost - Feature Selection</a>

# Question 7 : Evaluate on test set

We saved our final models in the comet.ml model registry, you can now pull all of these models and evaluate them programmatically.

## Test of our 5 models on the untouched 2019/20 regular season dataset :

|                               | Accuracy |           | Accuracy |                    | Accuracy |
|-------------------------------|----------|-----------|----------|--------------------|----------|
| Baseline_Model_Distance       | 0.914    | Final_DT  | 0.918    | xgb_model_feat_sel | 0.919    |
| Baseline_Model_Angle          | 0.914    | Final_NB  | 0.869    | xgb_model_grid     | 0.919    |
| Baseline_Model_Angle_Distance | 0.878    | Final_RF  | 0.918    |                    |          |
| Baseline_Random_Model         | 0.503    | Final_SVM | 0.914    |                    |          |

<table style="width:100%">
    <tr>
        <td><img src="/images/Validation_2019_R_Baseline Cumulative Percentage Of Goals.png"></td>
        <td><img src="/images/Validation_2019_R_Baseline Goal Rates.png"></td>
    </tr>
        <tr>
        <td><img src="/images/Validation_2019_R_Baseline Reliability.png"></td>
        <td><img src="/images/Validation_2019_R_Baseline ROC.png"></td>
    </tr>
    <tr>
        <td colspan="2"><center>XGBoost with feature selection (10 features)</center></td>
    </tr>
</table>

<table style="width:100%">
    <tr>
        <td><img src="/images/Validation_2019_R_xgb Cumulative Percentage Of Goals.png"></td>
        <td><img src="/images/Validation_2019_R_xgb Goal Rates.png"></td>
    </tr>
        <tr>
        <td><img src="/images/Validation_2019_R_xgb Reliability.png"></td>
        <td><img src="/images/Validation_2019_R_xgb ROC.png"></td>
    </tr>
    <tr>
        <td colspan="2"><center>XGBoost with feature selection (10 features)</center></td>
    </tr>
</table>

<table style="width:100%">
    <tr>
        <td><img src="/images/Validation_2019_R_Final Cumulative Percentage Of Goals.png"></td>
        <td><img src="/images/Validation_2019_R_Final Goal Rates.png"></td>
    </tr>
        <tr>
        <td><img src="/images/Validation_2019_R_Final Reliability.png"></td>
        <td><img src="/images/Validation_2019_R_Final ROC.png"></td>
    </tr>
    <tr>
        <td colspan="2"><center>XGBoost with feature selection (10 features)</center></td>
    </tr>
</table>


## Test of our 5 models on the untouched 2019/20 playoff season dataset :

|                               | Accuracy |           | Accuracy |                    | Accuracy |
|-------------------------------|----------|-----------|----------|--------------------|----------|
| Baseline_Model_Distance       | 0.907    | Final_DT  | 0.912    | xgb_model_feat_sel | 0.912    |
| Baseline_Model_Angle          | 0.901    | Final_NB  | 0.843    | xgb_model_grid     | 0.912    |
| Baseline_Model_Angle_Distance | 0.850    | Final_RF  | 0.912    |                    |          |
| Baseline_Random_Model         | 0.501    | Final_SVM | 0.907    |                    |          |

<table style="width:100%">
    <tr>
        <td><img src="/images/Validation_2019_P_Baseline Cumulative Percentage Of Goals.png"></td>
        <td><img src="/images/Validation_2019_P_Baseline Goal Rates.png"></td>
    </tr>
        <tr>
        <td><img src="/images/Validation_2019_P_Baseline Reliability.png"></td>
        <td><img src="/images/Validation_2019_P_Baseline ROC.png"></td>
    </tr>
    <tr>
        <td colspan="2"><center>XGBoost Base Model</center></td>
    </tr>
</table>

<table style="width:100%">
    <tr>
        <td><img src="/images/Validation_2019_P_xgb Cumulative Percentage Of Goals.png"></td>
        <td><img src="/images/Validation_2019_P_xgb Goal Rates.png"></td>
    </tr>
        <tr>
        <td><img src="/images/Validation_2019_P_xgb Reliability.png"></td>
        <td><img src="/images/Validation_2019_P_xgb ROC.png"></td>
    </tr>
    <tr>
        <td colspan="2"><center>XGBoost with feature selection (10 features)</center></td>
    </tr>
</table>

<table style="width:100%">
    <tr>
        <td><img src="/images/Validation_2019_P_Final Cumulative Percentage Of Goals.png"></td>
        <td><img src="/images/Validation_2019_P_Final Goal Rates.png"></td>
    </tr>
        <tr>
        <td><img src="/images/Validation_2019_P_Final Reliability.png"></td>
        <td><img src="/images/Validation_2019_P_Final ROC.png"></td>
    </tr>
    <tr>
        <td colspan="2"><center>XGBoost with feature selection (10 features)</center></td>
    </tr>
</table>




